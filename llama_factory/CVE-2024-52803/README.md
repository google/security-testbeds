# LlamaFactory CVE-2024-52803 - OS Command Injection

This testbed contains both vulnerable and patched versions of LlamaFactory to demonstrate CVE-2024-52803, a critical OS command injection vulnerability.

### Description

LlamaFactory is vulnerable to remote OS command injection through the `output_dir` parameter in the training process. The vulnerability arises from improper handling of user input where the `output_dir` value is passed unsanitized to Python's `Popen()` function with `shell=True`, allowing attackers to execute arbitrary OS commands.


## Setup

- Run Vulnerable Version Only

```bash
docker compose up llama-factory-vulnerable
```

The vulnerable instance will be available at **http://localhost:7860**

- Run Safe/Patched Version Only

```bash
docker compose up llama-factory-safe
```

The patched instance will be available at **http://localhost:7861**

- Run Both Versions Simultaneously

```bash
docker compose up
```

- **Vulnerable**: http://localhost:7860
- **Safe**: http://localhost:7861

Both services take 1-2 minutes to initialize. Wait for the log message:

```
Running on local URL:  http://0.0.0.0:7860
```

## Reproduce

The PoC uses the Gradio queue endpoints `/queue/join` and `/queue/data`.
Reference PoC: https://gist.github.com/superboy-zjc/f2d2b93ae511c445ba97e144b70e534d

### Python PoC

```sh
uv run --with requests poc_verify.py --url http://localhost:<port> --cmd "echo poc-vuln"
```

Run the PoC against the vulnerable instance and confirm command execution (log output). Then repeat against the safe instance and confirm there is no command output.

### Tsunami Scanner Verification

This testbed is designed to be verified using the Tsunami Security Scanner with an out-of-band callback server. The vulnerable Docker image includes `curl` to facilitate this.

1.  **Start the Tsunami Callback Server**:
    Follow the instructions in the `tsunami-security-scanner-callback-server` repository to build and run the callback server.

2.  **Run Tsunami Scanner**:
    Ensure the scanner can reach both the LLaMA Factory instance and the callback server.

    ```bash
    # Example command (adjust paths and IPs as needed)
    docker run --network host --rm \
      -v /path/to/tsunami.yaml:/usr/tsunami/tsunami.yaml \
      tsunami-scanner-full:latest \
      tsunami \
      --ip-v4-target=127.0.0.1 \
      --port-ranges-target=T:7860 \
      --detectors-include="LlamaFactory_CVE_2024_52803"
    ```

    *   **Vulnerable (Port 7860)**: Should report `VULNERABILITY_VERIFIED` and you should see a hit in the callback server logs.
    *   **Safe (Port 7861)**: Should not report the vulnerability.

## References

- https://github.com/advisories/GHSA-hj3w-wrh4-44vp
- https://gist.github.com/superboy-zjc/f2d2b93ae511c445ba97e144b70e534d
- https://nvd.nist.gov/vuln/detail/CVE-2024-52803
- https://github.com/hiyouga/LlamaFactory/commit/aa6a174d6822340022433c5ba38182b4932adecb

